{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmVtjN8Sb/bepZ24haR2uH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lAV_ct9s6Nfz"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Detectron2 installation."],"metadata":{"id":"161Cflax6hQY"}},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/detectron2.git\n","!python -m pip install -e detectron2"],"metadata":{"id":"mnEPpkZj6S3r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Version Controls"],"metadata":{"id":"Zlv5virF6ct_"}},{"cell_type":"code","source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"],"metadata":{"id":"kwx0GYpi6WpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"],"metadata":{"id":"sypAQfC_6kZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Register"],"metadata":{"id":"-wYSMDzw6pwB"}},{"cell_type":"code","source":["from detectron2.data.datasets import register_coco_instances\n","\n","register_coco_instances(\"my_dataset_train\", {}, \"path_train_annotations.json\", \"path_your_train_dataset\")\n","register_coco_instances(\"my_dataset_val\", {}, \"path_val_annotations.json\", \"path_your_val_dataset\")"],"metadata":{"id":"ntXMbVDv6r9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n","train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")"],"metadata":{"id":"tcEYUtmM7EU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n","val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")"],"metadata":{"id":"Hx6ISu7f7Eq1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizing Some Random Examples."],"metadata":{"id":"Iu3D4WTE7Tru"}},{"cell_type":"code","source":["from matplotlib import pyplot as plt\n","\n","for d in random.sample(train_dataset_dicts, 2):\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n","    vis = visualizer.draw_dataset_dict(d)\n","    plt.imshow(vis.get_image()[:, :, ::-1])\n","    plt.axis(False)\n","    plt.show()"],"metadata":{"id":"7mNRYAYv7Ft7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from detectron2.engine import DefaultTrainer\n","\n","# HYPERPARAMETERS\n","MODEL = \"path/to/mask2former/pkl\"\n","CONFIG = \"path/to/mask2former/yaml\"\n","\n","cfg = get_cfg()\n","cfg.OUTPUT_DIR = \"output_path\"\n","cfg.merge_from_file = (CONFIG)\n","cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n","cfg.DATASETS.TEST = (\"my_dataset_val\")\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = MODEL\n","cfg.SOLVER.IMS_PER_BATCH = 4  # Batch size\n","cfg.SOLVER.BASE_LR = 0.0001  # Learning_rate\n","cfg.INPUT.MASK_FORMAT='polygon'\n","cfg.SOLVER.MAX_ITER = 5    # Iteration\n","cfg.SOLVER.STEPS = []\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False) # If there is a pre-trained model, you can upload it."],"metadata":{"id":"DYlN1-Ue7Wcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train() # Start train"],"metadata":{"id":"Hau8rUXq7sNR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Save Config File"],"metadata":{"id":"kzdzvk4674Ot"}},{"cell_type":"code","source":["import yaml\n","config_yaml_path = \"path_output/output.yaml\" # Should be output.yaml at the end\n","with open(config_yaml_path, 'w') as file:\n","    yaml.dump(cfg, file)"],"metadata":{"id":"8Z7aL-1n70eN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inference & Evaluation"],"metadata":{"id":"Sfck5wFv765m"}},{"cell_type":"code","source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Threshold\n","predictor = DefaultPredictor(cfg)"],"metadata":{"id":"h1ak-mHk79Qs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Segment Random Images in Validation Dataset"],"metadata":{"id":"yFL9afTZ8TiI"}},{"cell_type":"code","source":["from detectron2.utils.visualizer import ColorMode\n","                       #val\n","for d in random.sample(val_dataset_dicts, 10):\n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=val_metadata,\n","                   scale=0.5,\n","                   instance_mode=ColorMode.IMAGE_BW\n","    )\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"7-SX5gKx8HPy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Metric Scores"],"metadata":{"id":"JiavpUoZ8XZz"}},{"cell_type":"code","source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"./output\")\n","val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n","print(inference_on_dataset(predictor.model, val_loader, evaluator))"],"metadata":{"id":"GP2I1HUv8YkE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Upload New Image"],"metadata":{"id":"yQ-ECCyg8dDP"}},{"cell_type":"code","source":["new_im = cv2.imread(\"new_image.jpg\")\n","outputs  = predictor(new_im)\n","\n","v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","\n","cv2_imshow(out.get_image()[:, :, ::-1])"],"metadata":{"id":"KyqCMLSJ8f1M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Segmenting and Saving Multiple Photos in a Folder"],"metadata":{"id":"T12w1zGs8nvl"}},{"cell_type":"code","source":["input_images_directory = \"test_path\"\n","\n","output_directory = \"test/test_results\"\n","\n","\n","for image_filename in os.listdir(input_images_directory):\n","    image_path = os.path.join(input_images_directory, image_filename)\n","    new_im = cv2.imread(image_path)\n","\n","    outputs = predictor(new_im)\n","\n","    v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","\n","    result_filename = os.path.splitext(image_filename)[0] + \"_result.png\"\n","    output_path = os.path.join(output_directory, result_filename)\n","\n","    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])\n","\n","print(\"All photos saved successfully!\")"],"metadata":{"id":"b8PrJbA38n-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","from skimage.measure import regionprops, label\n","\n","\n","# Image folder path\n","input_images_directory = \"test\"\n","\n","# Where to save the CSV file\n","output_csv_path = \"test_results/output_objects.csv\"  # Replace this with the path to your desired output CSV file\n","\n","\n","with open(output_csv_path, 'w', newline='') as csvfile:\n","    csvwriter = csv.writer(csvfile)\n","\n","\n","    csvwriter.writerow([\"File Name\", \"Class Name\", \"Object Number\", \"Area\", \"Centroid\", \"BoundingBox\"])  # Add more columns as needed for other properties\n","\n","    for image_filename in os.listdir(input_images_directory):\n","        image_path = os.path.join(input_images_directory, image_filename)\n","        new_im = cv2.imread(image_path)\n","\n","        outputs = predictor(new_im)\n","\n","        mask = outputs[\"instances\"].pred_masks.to(\"cpu\").numpy().astype(bool)\n","\n","\n","        class_labels = outputs[\"instances\"].pred_classes.to(\"cpu\").numpy()\n","\n","       # # Debugging: print class_labels and metadata.thing_classes\n","       # #print(\"Class Labels:\", class_labels)\n","       # #print(\"Thing Classes:\", train_metadata.thing_classes)\n","\n","        labeled_mask = label(mask)\n","        props = regionprops(labeled_mask)\n","\n","        for i, prop in enumerate(props):\n","            object_number = i + 1  # object number = 1 (i = 0 / i+1 = 1)\n","            area = prop.area\n","            centroid = prop.centroid\n","            bounding_box = prop.bbox\n","\n","            if i < len(class_labels):\n","                class_label = class_labels[i]\n","                class_name = train_metadata.thing_classes[class_label]\n","            else:\n","                class_name = 'Unknown'\n","\n","            csvwriter.writerow([image_filename, class_name, object_number, area, centroid, bounding_box])  # Add more columns as needed for other properties\n","\n","print(\"Object Information Saved to CSV.\")\n"],"metadata":{"id":"iWirIsIb9E_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","csv_file_path = \"test_results/output_objects.csv\"  # Update with your CSV file path\n","\n","df = pd.read_csv(csv_file_path)\n","\n","class_names = train_metadata.thing_classes\n","\n","\n","avg_objects_per_class = df.groupby([\"File Name\", \"Class Name\"])[\"Object Number\"].count().reset_index()\n","avg_objects_per_class = avg_objects_per_class.groupby(\"Class Name\")[\"Object Number\"].mean().reset_index()\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=\"Class Name\", y=\"Object Number\", data=avg_objects_per_class, ci=None, order=class_names)\n","plt.xticks(rotation=45)\n","plt.xlabel(\"Class Name\")\n","plt.ylabel(\"Average Number of Objects per Image\")\n","plt.title(\"Average Number of Objects per Image for Each Class\")\n","plt.tight_layout()\n","plt.show()\n","\n","\n","avg_area_per_class = df.groupby(\"Class Name\")[\"Area\"].mean().reset_index()\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=\"Class Name\", y=\"Area\", data=avg_area_per_class, ci=None, order=class_names)\n","plt.xticks(rotation=45)\n","plt.xlabel(\"Class Name\")\n","plt.ylabel(\"Average Area of Objects\")\n","plt.title(\"Average Area of Objects for Each Class\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"Y-hOi_ht9jFr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving Binary Masks"],"metadata":{"id":"h4D7cgg89879"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import torch\n","from detectron2.utils.visualizer import Visualizer\n","\n","input_images_directory = \"test\"\n","\n","output_directory = \"test_result_instance\"  # Replace this with the path to your desired output directory\n","\n","for image_filename in os.listdir(input_images_directory):\n","    image_path = os.path.join(input_images_directory, image_filename)\n","    new_im = cv2.imread(image_path)\n","\n","    outputs = predictor(new_im)\n","\n","    class_masks = {class_name: torch.zeros_like(outputs[\"instances\"].pred_masks[0], dtype=torch.uint8, device=torch.device(\"cuda:0\"))\n","                   for class_name in train_metadata.thing_classes}\n","\n","    for i, pred_class in enumerate(outputs[\"instances\"].pred_classes):\n","        class_name = train_metadata.thing_classes[pred_class]\n","        class_masks[class_name] = torch.where(outputs[\"instances\"].pred_masks[i].to(device=torch.device(\"cuda:0\")),\n","                                              i + 1,\n","                                              class_masks[class_name])\n","\n","    for class_name, class_mask in class_masks.items():\n","\n","        class_mask_np = class_mask.cpu().numpy()\n","\n","        class_filename = os.path.splitext(image_filename)[0] + f\"_{class_name}_result.png\"\n","        class_output_path = os.path.join(output_directory, class_filename)\n","\n","        cv2.imwrite(class_output_path, class_mask_np.astype(np.uint8))\n","\n","print(\"Segmentation of All Images Completed!\")"],"metadata":{"id":"alnkMQQH9tfh"},"execution_count":null,"outputs":[]}]}